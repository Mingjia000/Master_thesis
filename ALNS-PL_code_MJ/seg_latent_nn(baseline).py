# -*- coding: utf-8 -*-
"""seg_latent_nn(baseline).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q5KTfPUe5UgmeM9wVqIQANvwtPz781mM
"""

import numpy as np
import random
import torch
import torch.nn as nn
from torch.utils.data import Dataset
import pandas as pd
import torch.nn.functional as F
import biogeme.database as db
import biogeme.biogeme as bio
import biogeme.models as models
import biogeme.results as res
from biogeme.expressions import Beta, DefineVariable
import biogeme.expressions as ex

def decision_maker(r1,r2,real_compare,shipper_num,shipper):
  dm=np.zeros((shipper_num,5))
  for i in range (len(real_compare)):
    shipper_id=shipper[i]
    if real_compare[i]==0:
      for j in range (5):
        if r1[i,j]< r2[i,j]:
          dm[shipper_id,j]=dm[shipper_id,j]+1
        else:
          dm[shipper_id,j]=dm[shipper_id,j]-1
    elif real_compare[i]==1:
      for j in range (5):
        if r1[i,j] > r2[i,j]:
          dm[shipper_id,j]=dm[shipper_id,j]+1
        else:
          dm[shipper_id,j]=dm[shipper_id,j]-1
  
  sum = np.sum(np.abs(dm), axis=1)
  dm = dm / sum[:, np.newaxis] 
  return dm

class MyDataset(Dataset):
    def __init__(self, x_0, x_1, y):
        self.x_0_data = x_0
        self.x_1_data = x_1
        self.y_data = y
        self.length = len(self.y_data)

    def __getitem__(self, index):
        return self.x_0_data[index, :, :], self.x_1_data[index, :, :], self.y_data[index]

    def __len__(self):
        return self.length

#estimate reward, comparison by network
def calculate_estimated_result(x_0, x_1,batch_size,r):
    estimated_compare = torch.zeros(batch_size)
    estimated_r_0 = torch.zeros(batch_size)
    estimated_r_1 = torch.zeros(batch_size)

    state_0 = x_0
    state_1 = x_1
    estimated_r_0 = r(state_0)
    estimated_r_1 = r(state_1)
    for i in range (batch_size):
      if estimated_r_0[i] > estimated_r_1[i]:
          estimated_compare[i] = 0
      elif estimated_r_0[i] < estimated_r_1[i]:
          estimated_compare[i] = 1
      else:
          estimated_compare[i] = 0.5
  
    estimated_result = [estimated_r_0, estimated_r_1, estimated_compare]

    return estimated_result

#simulate shippers' comparison on transport plans  
def shipper_compare (reward_0,reward_1):
    compare = np.array([0 for i in range(len(reward_1))])
    for i in range(len(reward_1)):
        if reward_0[i] > reward_1[i]:
            compare[i] = 0
        elif reward_0[i] < reward_1[i]:
            compare[i] = 1
        else:
            compare[i] = 0
    return  compare  

def shipper_reward(route,h):
  reward = np.zeros(len(route[:,0]))
  mu, beta = 0, 1
  s = np.random.gumbel(mu, beta,len(route[:,0]))
  for i in range (len(route[:,0])):
      if h[i]==0:
            reward[i] = -10 * route[i, 0] - 8 * 5 * route[i, 1] - 5 * 5 *route[i, 2] - 2* 5 * route[i, 3]- 2* route[i, 4]
      elif h[i]==1:
            reward[i] = -10 * 5* route[i, 0] - 8  * route[i, 1] - 5  *route[i, 2] - 2 * route[i, 3]- 2* route[i, 4]
      elif h[i]==2:
            reward[i] = -10 *route[i, 0] - 8 * 2.5 * route[i, 1] - 5 * 2.5 *route[i, 2] - 2* 5* route[i, 3]- 2* 5* route[i, 4]
      elif h[i]==3:
            reward[i] = -10* 5 *route[i, 0] - 8 * 5 * route[i, 1] - 5 * 5 *route[i, 2] - 2* route[i, 3]- 2* 5* route[i, 4]
  reward = reward + s
  return reward

def train_utility (train_dataloader,epochs,batch_size,r,learning_rate,s):
  optimizer = torch.optim.AdamW(r.parameters(), lr=learning_rate)
  for epoch in range(epochs):
    loss_sum = 0
    for step, (batch_x_0, batch_x_1, batch_y) in enumerate(train_dataloader):
        x0=batch_x_0[:,:,0].float()
        x1=batch_x_1[:,:,0].float()
        u1=r(x0)
        u2=r(x1)
        latent=s(batch_x_0[:,:,1].float())
        utility1=u1[:,0]*latent[:,0]+u1[:,1]*latent[:,1]+u1[:,2]*latent[:,2]+u1[:,3]*latent[:,3]
        utility2=u2[:,0]*latent[:,0]+u2[:,1]*latent[:,1]+u2[:,2]*latent[:,2]+u2[:,3]*latent[:,3]
        input =torch.cat((utility1.reshape(-1,1), utility2.reshape(-1,1)),1)
        
        target = batch_y.long()
        loss = criterion(input, target)
        # take gradient step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        loss_sum = loss + loss_sum

    #print(epoch, 'nn',loss_sum/(train_n/batch_size)) #real
    if (epoch + 1) % 10 == 0:
        print("Epoch [{}/100], Loss: {:.4f}".format(epoch + 1, loss_sum/(train_n/batch_size)))
  return r

def train_seg (train_dataloader,epochs,batch_size,r,learning_rate,s):
  optimizer = torch.optim.AdamW(s.parameters(), lr=learning_rate)
  for epoch in range(epochs):
    loss_sum = 0
    for step, (batch_x_0, batch_x_1, batch_y) in enumerate(train_dataloader):
        x0=batch_x_0[:,:,0].float()
        x1=batch_x_1[:,:,0].float()
        u1=r(x0)
        u2=r(x1)
        latent=s(batch_x_0[:,:,1].float())
        utility1=u1[:,0]*latent[:,0]+u1[:,1]*latent[:,1]+u1[:,2]*latent[:,2]+u1[:,3]*latent[:,3]
        utility2=u2[:,0]*latent[:,0]+u2[:,1]*latent[:,1]+u2[:,2]*latent[:,2]+u2[:,3]*latent[:,3]
        input =torch.cat((utility1.reshape(-1,1), utility2.reshape(-1,1)),1)
        target = batch_y.long()
        loss = criterion(input, target)
        # take gradient step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        loss_sum = loss + loss_sum

    #print(epoch, 'nn',loss_sum/(train_n/batch_size)) #real
    if (epoch + 1) % 10 == 0:
        print("Epoch [{}/100], Loss: {:.4f}".format(epoch + 1, loss_sum/(train_n/batch_size)))
  return r
def test(t1,t2,test_n,test_real_compare,r,s):
  incorrect=0
  index=[]
  c_index=[]
  u_test_state_0 = torch.from_numpy(t1[:,:,0]).float()
  u_test_state_1 = torch.from_numpy(t2[:,:,0]).float()        
  s_test_state = torch.from_numpy(t1[:,:,1]).float()

  u1=r(u_test_state_0)
  u2=r(u_test_state_1)
  latent=s(s_test_state)
  utility1=u1[:,0]*latent[:,0]+u1[:,1]*latent[:,1]+u1[:,2]*latent[:,2]+u1[:,3]*latent[:,3]
  utility2=u2[:,0]*latent[:,0]+u2[:,1]*latent[:,1]+u2[:,2]*latent[:,2]+u2[:,3]*latent[:,3]

  for i in range (len(latent)):
      if utility1[i] > utility2[i] and test_real_compare[i]==1:
          incorrect=incorrect+1
          index.append(test_h[i])
      elif utility1[i] < utility2[i] and test_real_compare[i]==0:
          incorrect=incorrect+1
          index.append(test_h[i])
      else:
          c_index.append(test_h[i])

  print('accuracy',1-incorrect/test_n)
  #print('predicted right(class mean)',sum(index)/len(index))
  #print('predicted wrong(class mean)',sum(c_index)/len(c_index))

class reward_net(nn.Module):
  def __init__(self, state_dim=5, action_dim=5):
        super(reward_net, self).__init__()
        self.linear1 = nn.Linear(state_dim,64)
        self.linear2 = nn.Linear(64, 64)
        self.linear3 = nn.Linear(64, action_dim)
        self.m=nn.Softmax()
  def forward(self, x):
        x = F.relu(self.linear1(x))
        x = F.relu(self.linear2(x))
        x = self.linear3(x)
        return x

class seg_net(nn.Module):
  def __init__(self, state_dim=5, action_dim=5):
        super(seg_net, self).__init__()
        self.linear1 = nn.Linear(state_dim,64)
        self.linear2 = nn.Linear(64, 64)
        self.linear3 = nn.Linear(64, action_dim)
        self.m=nn.Softmax()

  def forward(self, x):
        x = F.relu(self.linear1(x))
        x = F.relu(self.linear2(x))
        x = self.linear3(x)
        #x = self.m(x)
        return x

train_n=1000
test_n=300
shipper_num=30
# 2 class
shipper=np.random.randint(shipper_num, size=train_n)
shipper_h=np.random.randint(4, size=shipper_num)
h= shipper_h[shipper]

test_shipper=np.random.randint(shipper_num, size=test_n)
test_h= shipper_h[test_shipper]

r1= np.random.rand(train_n,5)#(train_n,4)
r2= np.random.rand(train_n,5)#(train_n,4)

t1= np.random.rand(test_n,5)#(test_n,4)
t2= np.random.rand(test_n,5)#(test_n,4)

reward_0 = shipper_reward (r1,h)
reward_1 = shipper_reward (r2,h)
real_compare = shipper_compare(reward_0,reward_1)
dm=decision_maker(r1,r2,real_compare,shipper_num,shipper)
x1=np.zeros((train_n,5,2))
x2=np.zeros((train_n,5,2))
x1[:,:,0]=r1
x1[:,:,1]=dm[shipper,:]
x2[:,:,0]=r2
x2[:,:,1]=dm[shipper,:]

test_reward_0 = shipper_reward (t1,test_h)
test_reward_1 = shipper_reward (t2,test_h)
test_real_compare = shipper_compare(test_reward_0,test_reward_1)
test_dm=decision_maker(t1,t2,test_real_compare,shipper_num,test_shipper)
e=test_dm[test_shipper,:]

batch_size = 64*8
train_dataset = MyDataset(x1, x2, real_compare)
train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)
learning_rate = 0.0005#0.001
epochs = 20
round=5
r = reward_net()
s = seg_net()

e1=np.zeros((test_n,5,2))
e2=np.zeros((test_n,5,2))
e1[:,:,0]=t1
e1[:,:,1]=dm[test_shipper,:]
e2[:,:,0]=t2
e2[:,:,1]=dm[test_shipper,:]
test(e1,e2,test_n,test_real_compare,r,s)
criterion = nn.CrossEntropyLoss()

for i in range (round):
  train_utility(train_dataloader,epochs,batch_size,r,learning_rate,s)
  test(e1,e2,test_n,test_real_compare,r,s)
  train_seg(train_dataloader,epochs,batch_size,r,learning_rate,s)
  test(e1,e2,test_n,test_real_compare,r,s)
  train_utility(train_dataloader,epochs,batch_size,r,learning_rate,s)
  test(e1,e2,test_n,test_real_compare,r,s)


n=train_n
df=pd.DataFrame()
df['CHOICE']=real_compare
#df['W_OTHER']=np.ones(n)-0.1
df['cost_1']=r1[:,0]
df['time_1']=r1[:,1]
df['delay_1']=r1[:,2]
df['emission_1']=r1[:,3]
df['trans_1']=r1[:,4]
df['A1']=np.ones(n)

df['cost_2']=r2[:,0]
df['time_2']=r2[:,1]
df['delay_2']=r2[:,2]
df['emission_2']=r2[:,3]
df['trans_2']=r2[:,4]
df['A2']=np.ones(n)


database = db.Database("pl",df)
globals().update(database.variables)

#Create parameters to be estimated
B_TIME1 = Beta('B_TIME1',0,None ,None ,0)
B_COST1 = Beta('B_COST1',0,None ,None ,0)
B_DELAY1 = Beta('B_DELAY1',0,None ,None ,0)
B_EMISSION1 = Beta('B_EMISSION1',0,None ,None ,0)
B_TRANS1 = Beta('B_TRANS1',0,None ,None ,0)

B_TIME2 = Beta('B_TIME2',0,None ,None ,0)
B_COST2 = Beta('B_COST2',0,None ,None ,0)
B_DELAY2 = Beta('B_DELAY2',0,None ,None ,0)
B_EMISSION2 = Beta('B_EMISSION2',0,None ,None ,0)
B_TRANS2 = Beta('B_TRANS2',0,None ,None ,0)

B_TIME3 = Beta('B_TIME3',0,None ,None ,0)
B_COST3 = Beta('B_COST3',0,None ,None ,0)
B_DELAY3 = Beta('B_DELAY3',0,None ,None ,0)
B_EMISSION3 = Beta('B_EMISSION3',0,None ,None ,0)
B_TRANS3 = Beta('B_TRANS3',0,None ,None ,0)

B_TIME4 = Beta('B_TIME4',0,None ,None ,0)
B_COST4 = Beta('B_COST4',0,None ,None ,0)
B_DELAY4 = Beta('B_DELAY4',0,None ,None ,0)
B_EMISSION4 = Beta('B_EMISSION4',0,None ,None ,0)
B_TRANS4 = Beta('B_TRANS4',0,None ,None ,0)

#Define the utility functions
V11 = B_COST1 * cost_1 + B_TIME1 * time_1 + B_DELAY1 * delay_1 + B_EMISSION1 * emission_1+ B_TRANS1 * trans_1
V12 = B_COST1 * cost_2 + B_TIME1 * time_2 + B_DELAY1 * delay_2 + B_EMISSION1 * emission_2+ B_TRANS1 * trans_2
# For latent class 2, whete the time coefficient is estimated
V21 = B_COST2 * cost_1 + B_TIME2 * time_1 + B_DELAY2 * delay_1 + B_EMISSION2 * emission_1+ B_TRANS2 * trans_1
V22 = B_COST2 * cost_2 + B_TIME2 * time_2 + B_DELAY2 * delay_2 + B_EMISSION2* emission_2+ B_TRANS2 * trans_2
# For latent class 3, whete the time coefficient is estimated
V31 = B_COST3 * cost_1 + B_TIME3 * time_1 + B_DELAY3 * delay_1 + B_EMISSION3 * emission_1+ B_TRANS3 * trans_1
V32 = B_COST3 * cost_2 + B_TIME3 * time_2 + B_DELAY3 * delay_2 + B_EMISSION3 * emission_2+ B_TRANS3 * trans_2
# For latent class 4, whete the time coefficient is estimated
V41 = B_COST4 * cost_1 + B_TIME4 * time_1 + B_DELAY4 * delay_1 + B_EMISSION4 * emission_1+ B_TRANS4 * trans_1
V42 = B_COST4 * cost_2 + B_TIME4 * time_2 + B_DELAY4 * delay_2 + B_EMISSION4 * emission_2+ B_TRANS4 * trans_2

#Associate utility functions with alternatives and associate availability of alternatives
V1 = {0: V11,1: V12}
V2 = {0: V21,1: V22}
V3 = {0: V31,1: V32}
V4 = {0: V41,1: V42}

av = {0: A1,1: A2}

# Class membership model
W_OTHER1 = Beta('W_OTHER1',0.25,0,1,0)
W_OTHER2 = Beta('W_OTHER2',0.2,0,1,0)
W_OTHER3 = Beta('W_OTHER3',0.25,0,1,0)
W_OTHER4 = Beta('W_OTHER4',0.5,0,1,0)
probClass1 = W_OTHER1
probClass2 = W_OTHER2
probClass3 = W_OTHER3
probClass4 = W_OTHER4

# The choice model is a discrete mixture of logit, with availability conditions
prob1 =  models.logit(V1,av,CHOICE)
prob2 =  models.logit(V2,av,CHOICE)
prob3 =  models.logit(V3,av,CHOICE)
prob4 =  models.logit(V4,av,CHOICE)
prob = probClass1 * prob1 + probClass2 * prob2 + probClass3 * prob3 +probClass4 * prob4
logprob =ex.log(prob)

#Estimate the model
#biogeme.generateHtml = False
#biogeme.generatePickle = False
biogeme  = bio.BIOGEME(database,logprob)
biogeme.modelName = "preferenceMixture"
#pickleFile ="preferenceMixture.pickle"

results = biogeme.estimate()
#print("Results=",results)


#Print results
betas = results.getBetaValues()
for k,v in betas.items():
    print(f"{k:10}=\t{v:.3g}")

Results = results.getEstimatedParameters()
print(Results)

#pickle.dump(results, open(pickleFile, 'wb'))

#general statistics
gs = results.getGeneralStatistics()

#for k,v in gs.items():
    #print("{}= {}".format(k.ljust(45),v[0]))

n=test_n
df_test=pd.DataFrame()
df_test['CHOICE']=test_real_compare
df_test['cost_1']=t1[:,0]
df_test['time_1']=t1[:,1]
df_test['delay_1']=t1[:,2]
df_test['emission_1']=t1[:,3]
df_test['trans_1']=t1[:,4]
df_test['A1']=np.ones(n)

df_test['cost_2']=t2[:,0]
df_test['time_2']=t2[:,1]
df_test['delay_2']=t2[:,2]
df_test['emission_2']=t2[:,3]
df_test['trans_2']=t2[:,4]
df_test['A2']=np.ones(n)

database_test = db.Database("pl_test",df_test)
globals().update(database_test.variables)

W_OTHER1 = Beta('W_OTHER1',0.25,0,1,0)
W_OTHER2 = Beta('W_OTHER2',0.2,0,1,0)
W_OTHER3 = Beta('W_OTHER3',0.25,0,1,0)
W_OTHER4 = Beta('W_OTHER4',0.5,0,1,0)
probClass1 = W_OTHER1
probClass2 = W_OTHER2
probClass3 = W_OTHER3
probClass4 = W_OTHER4

# The choice model is a discrete mixture of logit, with availability conditions
prob_11 = models.logit(V1, av, 0)
prob_12 = models.logit(V1, av, 1)
prob_21 = models.logit(V2, av, 0)
prob_22 = models.logit(V2, av, 1)
prob_31 = models.logit(V3, av, 0)
prob_32 = models.logit(V3, av, 1)
prob_41 = models.logit(V4, av, 0)
prob_42 = models.logit(V4, av, 1)

prob1 = probClass1 *prob_11 + probClass2 *prob_21 + probClass3  *prob_31+ probClass4 *prob_41
prob2 = probClass1 *prob_12 + probClass2 *prob_22 + probClass3 *prob_32+ probClass4 *prob_42
#biogeme = bio.BIOGEME(database_test, logprob)
simulate ={'Prob. 1':   prob1,'Prob. 2':  prob2}
biogeme = bio.BIOGEME(database_test, simulate)
biogeme.modelName = "logit_test"

#results = res.bioResults(pickleFile="preferenceMixture")
betaValues = results.getBetaValues ()
simulatedValues = biogeme.simulate(betaValues)
print(simulatedValues.head())
prob_max = simulatedValues.idxmax(axis=1)
prob_max = prob_max.replace({'Prob. 1': 0, 'Prob. 2': 1})

data = {'y_Actual':    df_test['CHOICE'],
        'y_Predicted': prob_max
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])


accuracy = np.diagonal(confusion_matrix.to_numpy()).sum()/confusion_matrix.to_numpy().sum()
print('Global accuracy of the model:', accuracy)

u1=r(torch.from_numpy(e1[:,:,0]).float())
latent=s(torch.from_numpy(e1[:,:,1]).float())
utility1=u1[:,0]*latent[:,0]+u1[:,1]*latent[:,1]+u1[:,2]*latent[:,2]+u1[:,3]*latent[:,3]
e1[:,0,0]=e1[:,0,0]+1
u2=r(torch.from_numpy(e1[:,:,0]).float())
#latent=s(torch.from_numpy(e1[:,:,1]).float())
utility2=u2[:,0]*latent[:,0]+u2[:,1]*latent[:,1]+u2[:,2]*latent[:,2]+u2[:,3]*latent[:,3]
#utility2=torch.nn.functional.normalize(utility2.reshape(-1,1), p=2.0)
#utility1=torch.nn.functional.normalize(utility1.reshape(-1,1), p=2.0)
#mean1=torch.mean(utility1)
#std1 = torch.std(utility1)
#utility1 = (utility1 - mean1) / std1
#mean2=torch.mean(utility2)
#std2 = torch.std(utility2)
#utility2 = (utility2 - mean2) / std2
print(utility2[:10]-utility1[:10])
print(test_h[:10])

"""test without segmentation"""

def train_utility (train_dataloader,epochs,batch_size,r,learning_rate):
  optimizer = torch.optim.AdamW(r.parameters(), lr=learning_rate)
  for epoch in range(epochs):
    loss_sum = 0
    for step, (batch_x_0, batch_x_1, batch_y) in enumerate(train_dataloader):
        x0=batch_x_0[:,:,0].float()
        x1=batch_x_1[:,:,0].float()
        u1=r(x0)
        u2=r(x1)
        #utility1=(u1[:,0]+u1[:,1]+u1[:,2]+u1[:,3])/4
        #utility2=(u2[:,0]+u2[:,1]+u2[:,2]+u2[:,3])/4
        utility1=u1[:,0]
        utility2=u2[:,0]
        input =torch.cat((utility1.reshape(-1,1), utility2.reshape(-1,1)),1)
        
        target = batch_y.long()
        loss = criterion(input, target)
        # take gradient step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        loss_sum = loss + loss_sum

    #print(epoch, 'nn',loss_sum/(train_n/batch_size)) #real
    if (epoch + 1) % 10 == 0:
        print("Epoch [{}/100], Loss: {:.4f}".format(epoch + 1, loss_sum/(train_n/batch_size)))
  return r

def test(t1,t2,test_n,test_real_compare,r):
  incorrect=0
  index=[]
  c_index=[]
  u_test_state_0 = torch.from_numpy(t1[:,:,0]).float()
  u_test_state_1 = torch.from_numpy(t2[:,:,0]).float()        

  u1=r(u_test_state_0)
  u2=r(u_test_state_1)
  #utility1=(u1[:,0]+u1[:,1]+u1[:,2]+u1[:,3])/4
  #utility2=(u2[:,0]+u2[:,1]+u2[:,2]+u2[:,3])/4
  utility1=u1[:,0]
  utility2=u2[:,0]
  for i in range (len(latent)):
      if utility1[i] > utility2[i] and test_real_compare[i]==1:
          incorrect=incorrect+1
          index.append(test_h[i])
      elif utility1[i] < utility2[i] and test_real_compare[i]==0:
          incorrect=incorrect+1
          index.append(test_h[i])
      else:
          c_index.append(test_h[i])

  print('accuracy',1-incorrect/test_n)


class reward_net(nn.Module):
  def __init__(self, state_dim=4, action_dim=4):
        super(reward_net, self).__init__()
        self.linear1 = nn.Linear(state_dim,64)
        self.linear2 = nn.Linear(64, 64)
        self.linear3 = nn.Linear(64, action_dim)
  def forward(self, x):
        x = F.relu(self.linear1(x))
        x = F.relu(self.linear2(x))
        x = self.linear3(x)
        return x

train_n=5000
test_n=2000
shipper_num=30
# 2 class
shipper=np.random.randint(shipper_num, size=train_n)
shipper_h=np.random.randint(8, size=shipper_num)
h= shipper_h[shipper]

test_shipper=np.random.randint(shipper_num, size=test_n)
test_h= shipper_h[test_shipper]

r1= np.random.rand(train_n,4)#(train_n,4)
r2= np.random.rand(train_n,4)#(train_n,4)

t1= np.random.rand(test_n,4)#(test_n,4)
t2= np.random.rand(test_n,4)#(test_n,4)

reward_0 = shipper_reward (r1,h)
reward_1 = shipper_reward (r2,h)
real_compare = shipper_compare(reward_0,reward_1)
dm=decision_maker(r1,r2,real_compare,shipper_num,shipper)
x1=np.zeros((train_n,4,2))
x2=np.zeros((train_n,4,2))
x1[:,:,0]=r1
x1[:,:,1]=dm[shipper,:]
x2[:,:,0]=r2
x2[:,:,1]=dm[shipper,:]

test_reward_0 = shipper_reward (t1,test_h)
test_reward_1 = shipper_reward (t2,test_h)
test_real_compare = shipper_compare(test_reward_0,test_reward_1)
test_dm=decision_maker(t1,t2,test_real_compare,shipper_num,test_shipper)
e=test_dm[test_shipper,:]

batch_size = 64*8
train_dataset = MyDataset(x1, x2, real_compare)
train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)
learning_rate = 0.001#0.001
epochs = 20
round=15
r = reward_net()

e1=np.zeros((test_n,4,2))
e2=np.zeros((test_n,4,2))
e1[:,:,0]=t1
e1[:,:,1]=dm[test_shipper,:]
e2[:,:,0]=t2
e2[:,:,1]=dm[test_shipper,:]
test(e1,e2,test_n,test_real_compare,r)
criterion = nn.CrossEntropyLoss()

for i in range (round):
  train_utility(train_dataloader,epochs,batch_size,r,learning_rate)
  test(e1,e2,test_n,test_real_compare,r)
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMuMRlYfab40A/K7kDEsvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mingjia000/Master_thesis/blob/main/preference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a_DLVigu_gx"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import numpy as np\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class nnPolicy(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, output_size):\n",
        "      #input_size= feature,output_size=out_feature\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_size),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        x = softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "htwS2SU8vq3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class nnReward(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, output_size):\n",
        "      #input_size= feature,output_size=out_feature\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_size),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "TsIAJpyUAJiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_attribute(s,time_interval,cost_matrix,connection_matrix):\n",
        "  #input: segment [state, state,state]; state=[activation, location]; 1,2,3,4,\n",
        "  #output: attribue maxtrix [cost, time]\n",
        "  # cost, time, reliability, emissions, risk of damage\n",
        "  route=np.zeros(cost_matrix.shape)\n",
        "  _s= s[s[:,0] == 1] #activation=1,activated\n",
        "  _s= _s[:,1] #terminal ID\n",
        "\n",
        "  _s_origin=_s[:-1]\n",
        "  _s_destinaiton=_s[1:]\n",
        "\n",
        "  route[_s_origin,_s_destinaiton]=1 #passed links\n",
        "\n",
        "  cost=np.sum(route*cost_matrix)\n",
        "  connection=np.sum(connection_matrix*route)\n",
        "\n",
        "  time= len(s)* time_interval\n",
        "\n",
        "  attribute=[connection, cost, time] #connection=0,full connected\n",
        "\n",
        "  return attribute\n"
      ],
      "metadata": {
        "id": "lRTYVxTr0STH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr = np.array([[1,1],[0,1],[0,2],[1,2],[1,3]])\n",
        "arr=arr[arr [:,0] == 1]\n",
        "arr=arr[:,1]\n",
        "route=np.zeros((5,5))\n",
        "route[arr,arr]=1\n",
        "print(route)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqTZzMTf3deh",
        "outputId": "e5f9b2c5-41e7-4c8e-f1fd-26a411e41086"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_reward_function (c):\n",
        "     #input: c attribute of a segment\n",
        "     #output: the ground true reward\n",
        "     r=c[0] #only cost\n",
        "     return r"
      ],
      "metadata": {
        "id": "FOO931Vd_4xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reward_interface(s1,s2,time_interval,cost_matrix):\n",
        "  #input: two segment\n",
        "  #output: preference [0,1],[1,0],[0.5,0.5],[can not compare]\n",
        "  #c1,c2: attribute of segments\n",
        "  c1=segment_attribute(s1,time_interval,cost_matrix) \n",
        "  c2=segment_attribute(s2,time_interval,cost_matrix)\n",
        "  r1_true= masked_reward_function(c1)    # self-defined, only value tcost\n",
        "  r2_true= masked_reward_function(c2)\n",
        "  if r1_true>r2_true:\n",
        "      pref=[1,0]\n",
        "  elif r1_true<r2_true:\n",
        "      pref=[0,1]\n",
        "  else:\n",
        "      pref=[0.5,0.5] \n",
        "  '''\n",
        "  if c1[0]==0 and c2[0]!=0:#segment越短越好？\n",
        "    pref=[1,0]\n",
        "  elif  c1[0]!=0 and c2[0]==0:\n",
        "    pref=[0,1]\n",
        "  elif  c1[0]==0 and c2[0]==0:\n",
        "    if r1_true>r2_true:\n",
        "      pref=[1,0]\n",
        "    elif r1_true<r2_true:\n",
        "      pref=[0,1]\n",
        "    else:\n",
        "      pref=[0.5,0.5]\n",
        "  #else:\n",
        "  #  print('can not compare')\n",
        "   '''\n",
        "\n",
        "  return pref"
      ],
      "metadata": {
        "id": "Fv18_B6my6zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_policy(output,connection_matrix):\n",
        "  output=output[connection_matrix==0]\n",
        "  id=np.arange(len(output))\n",
        "  output_id=output[id==0]\n",
        "  action=output_id[np.argmax(output)]\n",
        "  return action"
      ],
      "metadata": {
        "id": "MirN1Z3A8N6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size_policy= 2 # [current location, the connected info]，[[activation, current terminal]\n",
        "output_size_policy= 6 # the node number\n",
        "input_size_reward_predictor= #(current state, current action)\n",
        "output_size_reward_predictor= 1\n",
        "initial_reward=\n",
        "\n",
        "#state:activation, location\n",
        "#activation:next station\n",
        "'''\n",
        "find the optimal policy\n",
        "if activation=1, policy is implemented\n",
        "  next state is determined  [activation, same terminal]\n",
        "else:\n",
        "  determin the next state [activation, same terminal]\n",
        "\n",
        "find the optimal reward\n",
        "if the policy give a impossible route--hard reward function\n",
        "else: ask for feedback\n",
        "\n",
        "'''\n",
        "\n",
        "#define the network\n",
        "time_matrix=np.array([[0,1,2,0,0,0],\n",
        "                      [2,0,0,1,2,0],\n",
        "                      [2,0,0,2,2,0],\n",
        "                      [0,2,2,0,0,1],\n",
        "                      [0,2,2,0,0,2],\n",
        "                      [0,0,0,2,2,0]])\n",
        "\n",
        "cost_matrix=np.array([[0,2,1,0,0,0],\n",
        "                      [2,0,0,2,2,0],\n",
        "                      [2,0,0,2,1,0],\n",
        "                      [0,2,2,0,0,2],\n",
        "                      [0,2,2,0,0,1],\n",
        "                      [0,0,0,2,2,0]])\n",
        "#mode_matrix=\n",
        "connection_matrix=np.array([[0,0,0,1,1,1],\n",
        "                      [0,0,1,0,0,1],\n",
        "                      [0,1,0,0,0,1],\n",
        "                      [1,0,0,0,1,0],\n",
        "                      [1,0,0,1,0,0],\n",
        "                      [1,1,1,0,0,0]])\n",
        "#connection=0,full connected\n",
        "\n",
        "#intial reward, train the policy, exmine connection, give feedback, update reward\n"
      ],
      "metadata": {
        "id": "9Sjgnlzpx27j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}